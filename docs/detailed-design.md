# MCPO On-Demand MCP Bridge 詳細設計書

## 1. システム概要

### 1.1 目的

本システムは、OpenWebUI + MCPO 環境において、PowerPoint等の「ファイル生成系MCPサーバー」を数百人規模で安全に利用可能にすることを目的とする。

以下の要件を満たす：
- MCP/MCPOの同期モデルを維持
- マルチユーザー対応
- リソース分離の徹底
- 一時ファイルの確実な削除

### 1.2 背景と課題

既存のMCPサーバーは常駐プロセスを前提とした設計となっており、ファイル生成用途では以下の問題が発生する：

- メモリ常駐によるリソース消費
- 一時ファイルの肥大化
- ユーザー間での成果物混線リスク
- MCP仕様上、非同期ジョブやキューモデルが表現できない

本設計では、「1リクエスト = 1プロセス」という Ephemeral（短命）なプロセスモデルを採用することで、これらの課題を解決する。

### 1.3 設計の位置づけ

本設計は以下の特徴を持つ：

- MCP/MCPO仕様を逸脱しない正統な拡張
- 非同期・キューを導入せず、同期モデルを維持
- 「MCPサーバー = ジョブワーカー」という新しい解釈
- PowerPoint生成のような重いツール用途に特化した現実解

## 2. 要求仕様

### 2.1 機能要件

| ID | 要件 | 説明 |
|---|---|---|
| FR-1 | MCP/MCPO互換リクエスト受信 | MCPおよびMCPO仕様に準拠したリクエストを受信し処理する |
| FR-2 | リクエスト毎プロセス起動 | 各リクエストに対して独立したMCPサーバープロセスを起動する |
| FR-3 | 単一リクエスト処理後終了 | MCPサーバーは1つのリクエストを処理した後、即座に終了する |
| FR-4 | ファイルダウンロード機能 | 生成されたファイルをHTTPS経由でダウンロード可能にする |
| FR-5 | 自動ファイル削除 | 不要となったファイルを自動的に削除する |
| FR-6 | 複数MCPサーバー種類対応 | 異なる種類のMCPサーバーを同時にサポートする |

### 2.2 非機能要件

| ID | 要件 | 説明 |
|---|---|---|
| NFR-1 | 高同時実行性 | 数百の同時リクエストに耐える処理能力を持つ |
| NFR-2 | ユーザー分離 | ユーザー間で成果物が完全に分離される |
| NFR-3 | プロトコル準拠 | MCP/MCPOプロトコル仕様に完全準拠する |
| NFR-4 | ステートレス設計 | 実装はステートレスを基本とし、水平スケール可能とする |
| NFR-5 | 水平スケール対応 | Docker Compose replicasとnginxによるロードバランシング |

## 3. アーキテクチャ設計

### 3.1 全体構成

システムは以下のコンポーネントから構成される：

#### 論理構成

**ユーザーアクセスフロー：**
1. ユーザーブラウザからHTTPSでNginxにアクセス
2. Nginxがロードバランサーとして複数のMCPO Bridgeインスタンスに分散
3. Nginxが静的ファイルサーバーとしてバインドマウントされた./data/mcpo-jobsからファイルを配信

**OpenWebUIフロー：**
1. OpenWebUIコンテナからMCP/MCPO（JSON-RPC over HTTP）でNginxロードバランサーにリクエスト
2. NginxがMCPO On-Demand Bridgeコンテナ（複数インスタンス）に転送
3. Bridgeがリクエストごとにサブプロセスを起動
   - 作業ディレクトリ作成（./data/mcpo-jobs/（ジョブUUID））
   - MCPサーバープロセス起動
4. Ephemeral MCPサーバープロセスがファイルを生成（pptx、pdf等）
5. 生成ファイルはバインドマウントされた一時ファイルストアに保存
6. ユーザーブラウザがNginx経由でHTTPSダウンロード

#### Docker構成

- Nginxコンテナ：フロントエンドプロキシ、ロードバランサー、静的ファイル配信
- OpenWebUIコンテナ：ユーザーインターフェース（Volumeマウント）
- MCPO Bridgeコンテナ：複数インスタンス（replicasで制御、バインドマウント使用）
- すべてのコンテナが同一Docker Composeで管理される
- コンテナ間通信はDockerネットワーク経由
- 一時ファイルとログはローカルディレクトリにバインドマウント

### 3.2 デプロイメント構成

#### 開発環境
- Docker Compose による単一ホスト構成
- Nginx、OpenWebUI、MCPO Bridge（複数レプリカ）が同一ネットワーク上で動作
- バインドマウントによる一時ファイル管理

#### 本番環境（想定）
- 同様のDocker Compose構成
- 共有ストレージ（NFS、S3等）による一時ファイル管理も選択可能
- 外部ロードバランサーとの併用も可能

## 4. コンポーネント詳細設計

### 4.1 Nginx フロントエンド

#### 4.1.1 役割と責務

Nginxコンポーネントは以下の責務を持つ：

- MCPOエンドポイントへのロードバランシング
- 静的ファイル配信（生成されたファイルのダウンロード、有効期限チェックなし）
- リバースプロキシ機能
- アクセスログ記録
- HTTPSターミネーション（本番環境）

#### 4.1.2 エンドポイント設計

##### MCP/MCPOプロキシエンドポイント

- MCPOエンドポイント：/mcpo/{server-type}
  - 例：/mcpo/powerpoint
  - 処理：対応するMCPサーバータイプのBridgeインスタンスへプロキシ
  
- MCPエンドポイント：/mcp/{server-type}
  - 例：/mcp/powerpoint
  - 処理：MCPプロトコルでの通信をプロキシ

##### ファイルダウンロードエンドポイント

- パス：/files/{job-uuid}/{filename}
- メソッド：GET
- 処理：バインドマウントから直接ファイルを配信（シンプルな配信、有効期限チェックなし）
- キャッシュ：無効化（Cache-Control: no-cache）

#### 4.1.3 ロードバランシング設定

##### ステートレスモード

- アルゴリズム：ラウンドロビン
- ヘルスチェック：/health エンドポイントを定期的にチェック
- フェイルオーバー：unhealthyなインスタンスを自動除外
- セッションアフィニティ：不要

##### ステートフルモード

- アルゴリズム：ip_hash（クライアントIPベースのスティッキーセッション）
- ヘルスチェック：/health エンドポイントを定期的にチェック
- フェイルオーバー：unhealthyなインスタンスを自動除外
- セッションアフィニティ：必須（同一IPは同一インスタンスへルーティング）
- 詳細：セクション19「ステートフルMCPサーバー対応設計」を参照

#### 4.1.4 静的ファイル配信設定

- ドキュメントルート：バインドマウント ./data/mcpo-jobs
- ディレクトリリスティング：無効
- 有効期限チェック：なし（シンプルな配信）
- MIMEタイプ：自動判定

### 4.2 MCPO On-Demand Bridge

#### 4.2.1 役割と責務

Bridgeコンポーネントは以下の責務を持つ：

- MCP/MCPOエンドポイントの提供
- リクエスト受信（パススルー）
- ジョブIDの発行と管理
- 作業ディレクトリの作成
- MCPサーバープロセスの起動と監視
- プロセスとの標準入出力通信
- 処理完了まで同期ブロック
- MCPレスポンスをそのまま返却
- メタデータ更新

#### 4.2.2 技術スタック

- 実装言語：Python 3.11以上
- Webフレームワーク：FastAPI
- 非同期処理：asyncio
- プロセス管理：subprocess モジュール
- HTTPサーバー：Uvicorn
- Docker基盤：Python公式イメージ

#### 4.2.3 主要モジュール構成

システムは以下のモジュールで構成される：

##### エンドポイントモジュール

- MCP/MCPOプロトコルエンドポイントの実装
- サーバータイプごとのエンドポイント提供
- リクエストのパススルー処理
- レスポンスの透過的返却

##### ジョブ管理モジュール

- UUID v4 によるジョブID発行
- ジョブメタデータの管理（作成時刻、状態）
- ジョブディレクトリの作成
- ジョブ状態の追跡

##### プロセス実行モジュール

- MCPサーバープロセスの起動
- 標準入出力パイプの管理
- プロセス監視とタイムアウト処理
- プロセス終了待機と同期ブロック
- 標準出力からのJSON解析
- エラーハンドリングと例外処理

##### ガーベジコレクションモジュール

- 定期的な古いファイル検査
- ディレクトリ削除処理
- 起動時の孤児ディレクトリクリーンアップ
- 安全な削除処理（パス検証）

##### 設定管理モジュール

- MCPサーバー設定ファイル読み込み
- JSON形式設定パース
- 環境変数からの設定オーバーライド
- 設定バリデーション

#### 4.2.4 MCPサーバー設定仕様

BridgeはClaude等で使用されるMCPサーバー設定JSON形式を使用する。

##### 設定ファイル構造

設定ファイルは以下の構造を持つ：

- ルートオブジェクトに「mcpServers」キーが存在
- 各サーバー定義はサーバー名をキーとするオブジェクト
- サーバー定義には「command」と「args」が必須
- 「env」キーでサーバー固有の環境変数を指定可能

##### サーバー定義の要素

各MCPサーバー定義には以下が含まれる：

- command：実行するコマンドパス（絶対パスまたは相対パス）
- args：コマンドライン引数の配列
- env：環境変数のキーバリューマップ（オプショナル）
- mode：実行モード（"stateful" / "stateless"、オプショナル、デフォルト: "stateless"）
- idle_timeout：アイドルタイムアウト秒数（オプショナル、modeが"stateful"の場合のみ有効、デフォルト: 1800）
- max_processes_per_ip：IPアドレスごとの最大プロセス数（オプショナル、modeが"stateful"の場合のみ有効、デフォルト: 1）

##### 設定ファイルの配置

- コンテナ内パス：/app/config/mcp-servers.json
- ソースコード配下のconfigディレクトリに配置
- サンプル設定：config/mcp-servers.json.example（Office-PowerPoint-MCP-Serverを使用）
- 設定変更時はコンテナ再起動が必要

#### 4.2.5 並行実行制御

同時実行制御のため以下を実装：

- asyncio.Semaphore による同時起動プロセス数制限
- デフォルト上限：CPU コア数 × 4
- 環境変数による上限カスタマイズ可能
- 上限到達時は429 Too Many Requests を返却

#### 4.2.6 タイムアウト設定

プロセス実行のタイムアウト管理：

- デフォルトタイムアウト：300秒（5分）
- 環境変数による調整可能
- タイムアウト時はプロセス強制終了（SIGTERM → SIGKILL）
- クライアントには504 Gateway Timeout を返却

### 4.3 Ephemeral MCP Server

#### 4.3.1 特性と要件

Ephemeral（短命）MCPサーバーは以下の特性を持つ：

- 1リクエスト = 1プロセスの原則
- 起動時に作業ディレクトリを引数または環境変数で受け取る
- 標準入力からMCPリクエストJSONを読み取る
- 標準出力にMCPレスポンスJSONを出力
- 処理完了後は即座にプロセス終了（exit code 0）
- エラー時は標準エラー出力にメッセージ出力後、非ゼロで終了

#### 4.3.2 実装条件

MCPサーバー実装は以下を満たす必要がある：

- MCP標準仕様に準拠したJSON-RPC通信
- ステートレスな処理（前回実行結果に依存しない）
- 適切なエラーハンドリングと終了コード
- タイムアウト内での処理完了

#### 4.3.3 対応MCPサーバー例

以下のようなMCPサーバーが利用可能：

- Office-PowerPoint-MCP-Server（GongRzhe/Office-PowerPoint-MCP-Server）
  - npxコマンドで起動：npx -y @gongrzhe/office-powerpoint-mcp-server
  - Node.js製のため、DockerfileでNode.jsインストールが必要
  - npxが自動的にパッケージをダウンロード・実行
- Excel-MCP-Server（haris-musa/excel-mcp-server）
  - uvxコマンドで起動：uvx excel-mcp-server stdio
  - Python製のため、Dockerfileでuvインストールが必要
  - uvxが自動的にPython環境を管理・実行
- PDF生成サーバー（Python製の場合はuvxも選択肢）
- Excel生成サーバー
- 画像生成サーバー
- その他ファイル生成系MCPサーバー
  - Node.js製：npx または node コマンドで実行
  - Python製：uvx または python コマンドで実行

### 4.4 一時ファイル管理

#### 4.4.1 ディレクトリ構造

一時ファイルは以下の構造で管理される：

**ルートディレクトリ：** ./data/mcpo-jobs/

**各ジョブディレクトリ：** ｛ジョブUUID｝/
- request.json：受信したMCPリクエスト
- response.json：MCPサーバーからのレスポンス
- metadata.json：ジョブメタデータ
- output.pptx：生成ファイル（例）
- server.log：MCPサーバーログ（オプション）

#### 4.4.2 ディレクトリライフサイクル

各ジョブディレクトリは以下のライフサイクルを持つ：

- 作成：リクエスト受信時に作成
- 利用：MCPサーバープロセスによるファイル生成
- 保持：処理完了後も保持
- 削除：ガーベジコレクタにより定期的に削除

#### 4.4.3 メタデータ管理

metadata.jsonには以下の情報を記録：

- job_id：ジョブの一意識別子
- server_name：使用したMCPサーバー名
- created_at：作成日時（ISO 8601形式）
- status：ジョブ状態（processing, completed, failed）
- request：受信したMCPリクエスト
- response：MCPサーバーレスポンス（処理完了後）
- error：エラーメッセージ（失敗時のみ）

#### 4.4.4 セキュリティ考慮

ファイルセキュリティのため以下を実施：

- job-uuidは推測困難なUUID v4を使用
- シンボリックリンク攻撃対策（パス正規化チェック）

#### 4.4.5 ストレージ設計

Docker環境では以下のストレージ設計を採用：

- バインドマウント：./data/mcpo-jobs
- コンテナ内マウントポイント：/tmp/mcpo-jobs
- 全Bridgeインスタンスで共有
- .gitignoreで除外

## 5. 処理フロー設計

### 5.1 正常系処理シーケンス

#### 全体フロー

1. OpenWebUIからMCP/MCPOリクエスト送信
2. NginxがリクエストをBridgeインスタンスにロードバランス
3. Bridge でリクエスト受信（パススルー）
4. UUID によるジョブID発行
5. ジョブディレクトリ作成（./data/mcpo-jobs/{job-uuid}/）
6. メタデータファイル作成
7. リクエストJSONをファイル保存
8. MCPサーバー設定から対象サーバー選択
9. コマンドライン引数組み立て
10. MCPサーバープロセス起動
11. 標準入力にリクエスト送信
12. 標準出力からレスポンス読み取り（同期ブロック）
13. プロセス終了待機
14. メタデータ更新（status=completed）
15. MCPレスポンスをそのまま返却

#### リクエスト処理の詳細フロー

##### Phase 1: リクエスト受付

- HTTPリクエストボディからJSON抽出
- JSON-RPCフォーマット検証（基本的なもののみ）
- パスパラメータからMCPサーバータイプ抽出
- 対応MCPサーバーの存在確認

##### Phase 2: ジョブ準備

- UUID v4生成
- 現在時刻取得
- ジョブディレクトリ作成
- メタデータJSON作成

##### Phase 3: プロセス実行

- MCPサーバー設定読み込み
- コマンド構築
- 環境変数準備
- subprocess.Popen でプロセス起動
- 標準入力へリクエストJSON書き込み
- 標準出力からレスポンスJSON読み取り
- タイムアウト監視
- プロセス終了コード確認

##### Phase 4: レスポンス処理

- メタデータ更新
- MCPレスポンスをそのまま返却（変更なし）
- HTTPレスポンス返却

### 5.2 異常系処理フロー

#### タイムアウト発生時

1. タイムアウト検出
2. MCPサーバープロセスにSIGTERM送信
3. 10秒待機
4. まだ終了していなければSIGKILL送信
5. エラーログ記録
6. ジョブステータスを「failed」に更新
7. クライアントに504エラー返却

#### MCPサーバー異常終了時

1. 非ゼロ終了コード検出
2. 標準エラー出力取得
3. エラーログ記録
4. ジョブステータスを「failed」に更新
5. エラーメッセージをそのまま返却

#### MCPサーバーがエラーを返さない場合

1. MCPサーバーが正常終了（exit code 0）
2. ファイルが存在しなくてもエラーとしない
3. MCPレスポンスをそのまま返却
4. ジョブステータスを「completed」に更新

#### 並行実行制限到達時

1. Semaphore 取得試行
2. 即座に取得できない場合
3. リトライせず429エラー返却
4. Retry-Afterヘッダー付与
5. クライアント側でリトライ推奨

#### ディスク容量不足時

1. ファイル書き込み時にOSError検出
2. エラーログ記録
3. 部分的に作成されたファイル削除
4. ジョブディレクトリ削除
5. クライアントに507エラー返却

### 5.3 ファイルダウンロードフロー（Nginx経由）

#### ダウンロードリクエスト処理（Nginx）

1. ダウンロードURLにアクセス（GET /files/{job-uuid}/{filename}）
2. job-uuid抽出
3. ファイルパス構築
4. ファイル存在確認
5. MIME type判定
6. Content-Dispositionヘッダー設定
7. ファイルストリーミング送信

## 6. API仕様設計

### 6.1 エンドポイント一覧

#### 6.1.1 MCPOエンドポイント（複数サーバータイプ対応）

各MCPサーバータイプごとに独立したエンドポイントを提供：

- パス：/mcpo/{server-type}
- 例：
  - /mcpo/powerpoint
  - /mcpo/pdf-generator
- メソッド：POST
- Content-Type：application/json
- プロトコル：JSON-RPC 2.0

#### 6.1.2 MCPエンドポイント（複数サーバータイプ対応）

各MCPサーバータイプごとに独立したエンドポイントを提供：

- パス：/mcp/{server-type}
- 例：
  - /mcp/powerpoint
  - /mcp/pdf-generator  
- メソッド：POST
- Content-Type：application/json
- プロトコル：MCP標準プロトコル

#### 6.1.3 ヘルスチェックエンドポイント

- パス：/health
- メソッド：GET
- レスポンス：JSON

### 6.2 MCPOエンドポイント詳細

#### リクエスト形式

JSON-RPC 2.0形式のリクエストを受け付け、そのままMCPサーバーに転送：

- jsonrpc：バージョン文字列（固定値「2.0」）
- method：呼び出すツール名（MCPサーバーで定義されたツール）
- params：ツールパラメータオブジェクト（バリデーションなし）
- id：リクエストID（数値または文字列）

#### レスポンス形式

MCPサーバーからのレスポンスをそのまま返却：

- Bridge側でレスポンスの内容を変更しない
- MCPサーバーが生成したJSONをそのままクライアントに転送
- エラーレスポンスもMCPサーバーの形式をそのまま使用

### 6.3 MCPエンドポイント詳細

#### リクエスト形式

MCP標準プロトコルのリクエストを受け付け、そのままMCPサーバーに転送：

- MCP仕様に従ったリクエスト形式
- Bridgeではバリデーションを行わず、MCPサーバーに委譲

#### レスポンス形式

MCPサーバーからのレスポンスをそのまま返却：

- Bridge側でレスポンスの内容を変更しない
- MCPサーバーが生成したレスポンスをそのままクライアントに転送

### 6.4 ヘルスチェックエンドポイント

#### エンドポイント仕様

- メソッド：GET
- パス：/health
- レスポンス：JSON

#### レスポンス内容

- status：健全性ステータス（ok / degraded / down）
- timestamp：チェック実行時刻
- version：Bridgeバージョン
- uptime：稼働時間（秒）

#### 判定基準

- 正常：すべてのコンポーネントが動作中
- 劣化：一部リソースが制限に近い
- 停止：重大な問題発生



## 7. 環境変数設計

### 7.1 Bridge設定用環境変数

#### 基本設定

- MCPO_CONFIG_FILE：MCP設定ファイルパス（デフォルト：/app/config/mcp-servers.json）
- MCPO_JOBS_DIR：ジョブディレクトリルート（デフォルト：/tmp/mcpo-jobs）
- MCPO_BASE_URL：ダウンロードURL用ベースURL（デフォルト：http://nginx）
- MCPO_MAX_CONCURRENT：最大同時実行数（デフォルト：CPU数×4）
- MCPO_TIMEOUT：プロセスタイムアウト（秒）（デフォルト：300）
- MCPO_LOG_LEVEL：ログレベル（デフォルト：INFO）

#### ステートフル設定

- MCPO_STATEFUL_ENABLED：ステートフル機能の有効化（デフォルト：true）
- MCPO_STATEFUL_DEFAULT_IDLE_TIMEOUT：デフォルトアイドルタイムアウト秒数（デフォルト：1800）
- MCPO_STATEFUL_MAX_PROCESSES_PER_IP：IPごとの最大プロセス数（デフォルト：1）
- MCPO_STATEFUL_MAX_TOTAL_PROCESSES：全体の最大プロセス数（デフォルト：100）
- MCPO_STATEFUL_CLEANUP_INTERVAL：クリーンアップ間隔秒数（デフォルト：300）

### 7.2 MCPサーバー実行時環境変数

MCPサーバープロセスに渡される環境変数：

- MCPO_WORKDIR：作業ディレクトリパス
- MCPO_JOB_ID：ジョブID
- その他、mcp-servers.jsonのenv設定

## 8. セキュリティ設計

### 8.1 基本方針

本システムでは、以下のセキュリティ方針を採用：

- 入力検証はすべてMCPサーバーに委譲
- Dockerコンテナはroot権限で実行
- シンプルな設計を優先

### 8.2 実施するセキュリティ対策

#### パス検証

- ジョブディレクトリパス正規化
- 親ディレクトリトラバーサル防止
- シンボリックリンク検出
- ホワイトリストベースパス検証

#### ファイル名検証

- 許可文字制限（英数字、ハイフン、アンダースコア、ドット）
- 長さ制限（255バイト以内）

#### Docker セキュリティ

##### イメージセキュリティ

- 公式Pythonイメージをベースに使用
- 最小限のパッケージインストール
- 定期的なイメージ更新
- 脆弱性スキャン実施

##### ネットワークセキュリティ

- 内部ネットワーク分離
- 不要ポート非公開
- TLS通信（本番環境）

## 9. スケーラビリティ設計

### 9.1 垂直スケール（単一インスタンス）

#### CPU拡張

- マルチコアCPUによる並列処理
- asyncioによる非同期I/O活用
- Semaphoreによる並行数最適化

#### メモリ拡張

- ファイルストリーミング送信によるメモリ節約
- ジョブメタデータの軽量化
- 不要オブジェクトの早期解放

#### ストレージ拡張

- ディレクトリサイズ拡張
- 古いファイルの積極的削除
- ストレージ使用量監視

### 9.2 水平スケール（複数インスタンス）

#### Docker Compose Replicas

- docker-compose.ymlでreplicas設定
- 同一設定の複数Bridgeインスタンス起動
- 自動的にNginxロードバランサー配下に配置

#### ステートレス設計

- インスタンス間で状態共有なし
- セッション情報なし
- ジョブIDによる一意性担保

#### Nginxロードバランシング

- ラウンドロビン分散
- ヘルスチェック連動
- セッションアフィニティ不要
- フェイルオーバー自動処理

#### 共有ストレージ

- バインドマウントで全インスタンス共有
- 全インスタンスが同一ストレージアクセス
- ダウンロードリクエストはどのインスタンスでも処理可能（Nginx経由）

### 9.3 性能目標

#### レスポンスタイム

- MCPリクエスト受信からレスポンス返却まで：平均5秒以内
- ファイルダウンロード開始まで：1秒以内

#### スループット

- 単一インスタンス：10リクエスト/秒
- 複数インスタンス：100リクエスト/秒以上

#### 同時接続数

- 単一インスタンス：50並行処理
- 複数インスタンス：500並行処理以上

## 10. ガーベジコレクション設計

### 10.1 削除対象の判定

#### 古いジョブ

- 作成日時から一定時間経過したジョブ（デフォルト24時間）
- metadata.jsonのcreated_at参照

#### 孤児ディレクトリ

- metadata.jsonが存在しないディレクトリ
- 作成から一定時間経過（デフォルト24時間）
- 異常終了等で残存したディレクトリ

### 10.2 削除タイミング

#### 定期実行（cron方式）

- 実行間隔：1時間毎（デフォルト）
- バックグラウンドタスクとして実行
- asyncioスケジューラー利用

#### 起動時クリーンアップ

- Bridge起動時に1回実行
- 前回異常終了時の残存ファイル削除
- 整合性確保

#### cron設定例

外部cronジョブでガーベジコレクションを実行する場合の設定例：

**毎時0分に実行する場合：**
- cron式：0 * * * *
- 実行コマンド：docker exec mcpo-bridge python -m src.utils.gc_jobs

**毎日午前3時に実行する場合：**
- cron式：0 3 * * *
- 実行コマンド：docker exec mcpo-bridge python -m src.utils.gc_jobs

**ホストマシンから直接ディレクトリをクリーンアップする場合：**
- cron式：0 * * * *
- 実行内容：findコマンドを使用して、24時間以上経過したジョブディレクトリを削除
- パス：/path/to/data/mcpo-jobs
- オプション：-mindepth 1 -maxdepth 1 -type d -mtime +1 -exec rm -rf

### 10.3 削除処理フロー

#### Phase 1: スキャン

1. ./data/mcpo-jobs ディレクトリ走査
2. 各ジョブディレクトリのmetadata.json読み込み
3. created_at確認
4. 削除対象リスト作成

#### Phase 2: 削除実行

1. 削除対象ディレクトリに対して順次処理
2. ディレクトリ内全ファイル削除
3. ディレクトリ自体を削除
4. 削除成功ログ記録

#### Phase 3: エラーハンドリング

1. 削除失敗時はログ記録
2. 次回GC実行時にリトライ

### 10.4 安全性担保

#### パス検証

- 削除対象が./data/mcpo-jobs配下か厳密確認
- 親ディレクトリ削除防止
- シンボリックリンク追跡禁止

#### ログ記録

- 削除ジョブID記録
- 削除日時記録
- エラー詳細記録

## 11. エラーハンドリング設計

### 11.1 エラー分類

#### レベル1：リクエストエラー

- クライアント起因のエラー
- 4xxステータスコード
- リトライ不要

#### レベル2：処理エラー

- MCPサーバー起因のエラー
- 5xxステータスコード
- リトライ可能な場合あり

#### レベル3：システムエラー

- Bridge自体の障害
- 503ステータスコード
- リトライ推奨

### 11.2 エラーレスポンス設計

#### 基本方針

MCPサーバーからのエラーレスポンスをそのまま返却：

- Bridgeでエラーメッセージを加工しない
- MCPサーバーのエラー形式を保持
- トレース情報もMCPサーバーの出力をそのまま使用

### 11.3 ログ設計

#### ログレベル

- DEBUG：デバッグ情報
- INFO：通常動作ログ
- WARNING：警告（処理は継続）
- ERROR：エラー（処理失敗）
- CRITICAL：致命的エラー（サービス停止）

#### ログ出力先

- 標準出力（Dockerログに集約）
- ログディレクトリに永続化（./data/mcpo-logs、バインドマウント）
- 本番環境では外部ログ集約サービス連携

#### ログフォーマット

- JSON形式
- タイムスタンプ、ログレベル、メッセージ、コンテキスト情報含む
- トレースIDによるリクエスト追跡



## 12. Docker化設計

### 12.1 Dockerfile設計方針

#### ベースイメージ

- 公式Pythonイメージ使用（python:3.11）
- セキュリティアップデート適用済みイメージ選定
- root権限での実行
- シンプルな単一ステージビルド

#### レイヤー最適化

- 変更頻度の低いコマンドを先に配置
- キャッシュ効率最大化
- 不要ファイル除外

### 12.2 ディレクトリ構造

コンテナ内ディレクトリ配置：

**/app/ ディレクトリ：**
- main.py：アプリケーションエントリーポイント
- requirements.txt：Python依存パッケージ
- config/：設定ファイルディレクトリ（ソースコード配下）
  - mcp-servers.json：MCPサーバー定義
  - mcp-servers.json.example：サンプル設定
- src/：ソースコードディレクトリ
  - api/：APIエンドポイント
  - core/：コアロジック
  - models/：データモデル
  - utils/：ユーティリティ

**/tmp/mcpo-jobs/ ディレクトリ：**
- 一時ファイル作業領域（バインドマウント）

**/var/log/mcpo/ ディレクトリ：**
- ログディレクトリ（バインドマウント）

### 12.3 依存パッケージ管理

#### Python依存パッケージ

requirements.txtで管理する主要パッケージ：

- FastAPI：Webフレームワーク
- Uvicorn：ASGIサーバー
- Pydantic：データバリデーション
- aiofiles：非同期ファイルI/O
- python-multipart：ファイルアップロード対応

#### システムパッケージ

実行時に必要なパッケージ：

- curl：ヘルスチェック用
- ca-certificates：HTTPS通信用
- nodejs：Node.js製MCPサーバー実行用（office-powerpoint-mcp-server等、npx経由）
- npm：Node.jsパッケージマネージャー（Node.jsに同梱）
- uv：Python製MCPサーバー実行用（excel-mcp-server等、uvx経由）

**推奨事項：**
- 様々なMCPサーバーに対応できるよう、npmとuvの両方をDockerfileにインストールすることを推奨します
- これにより、Node.js製とPython製の両方のMCPサーバーを柔軟に利用できます

### 12.4 ストレージ設計

#### 一時ファイルストレージ

- バインドマウント：./data/mcpo-jobs
- マウントポイント：/tmp/mcpo-jobs
- 全Bridgeインスタンスで共有
- .gitignoreで除外

#### ログストレージ

- バインドマウント：./data/mcpo-logs
- マウントポイント：/var/log/mcpo
- 永続化ログ保存
- 全Bridgeインスタンスで共有
- .gitignoreで除外

### 12.5 ネットワーク設計

#### 内部ネットワーク

- ネットワーク名：mcpo-network
- ドライバー：bridge
- Nginx、OpenWebUI、Bridgeが接続

#### ポート公開

- Nginxポート：80（HTTP）、443（HTTPS、本番環境）
- Bridgeポート：8080（内部のみ、Nginx経由）
- OpenWebUIポート：内部のみ（Nginx経由）

### 12.6 環境変数設計

#### 必須環境変数

- MCPO_BASE_URL：ダウンロードURL生成用
- 例：http://nginx

#### オプション環境変数

- MCPO_MAX_CONCURRENT：最大同時実行数
- MCPO_TIMEOUT：タイムアウト時間
- MCPO_LOG_LEVEL：ログレベル

### 12.7 ヘルスチェック設計

#### Dockerヘルスチェック

- チェック方法：HTTP GET /health
- 間隔：30秒
- タイムアウト：10秒
- リトライ：3回
- 開始遅延：10秒

#### ヘルスチェック判定

- 成功：200 OK応答
- 失敗：タイムアウトまたは非200応答
- unhealthy判定後の動作：Docker依存

## 13. Docker Compose設計

### 13.1 サービス定義

#### Nginxサービス

- サービス名：nginx
- イメージ：公式nginxイメージ
- ポート：ホスト80 → コンテナ80
- バインドマウント：nginx設定、./data/mcpo-jobs（読み取り専用）
- ネットワーク：mcpo-network
- 設定：ロードバランシング、静的ファイル配信

#### OpenWebUIサービス

- サービス名：openwebui
- イメージ：公式OpenWebUIイメージ
- ポート：内部のみ（Nginx経由）
- ボリューム：openwebui-data（永続化）
- ネットワーク：mcpo-network
- 依存関係：mcpo-bridge（depends_on）

#### MCPO Bridgeサービス

- サービス名：mcpo-bridge
- ビルド：ローカルDockerfile使用
- ポート：内部8080（Nginx経由のみ）
- バインドマウント：./data/mcpo-jobs、./data/mcpo-logs
- ネットワーク：mcpo-network
- ヘルスチェック：有効
- デプロイ：replicas設定で複数インスタンス

### 13.2 ストレージ定義

#### OpenWebUIデータ（ボリューム）

- ボリューム名：openwebui-data
- 用途：OpenWebUIデータ永続化

#### MCPO Bridge データ（バインドマウント）

- ./data/mcpo-jobs：一時ファイル（.gitignore）
- ./data/mcpo-logs：ログファイル（.gitignore）

### 13.3 ネットワーク定義

#### mcpo-network

- ドライバー：bridge
- 内部通信専用
- DNSによるサービス名解決

### 13.4 スケール設定

#### Replicas設定

- mcpo-bridgeサービスにdeploy.replicas設定
- デフォルト：3インスタンス
- Nginxが自動的にロードバランシング

### 13.5 起動順序制御

#### depends_on設定

- OpenWebUIはmcpo-bridgeに依存
- mcpo-bridgeのhealthy確認後にOpenWebUI起動
- condition: service_healthy 利用

#### 起動シーケンス

1. ネットワーク作成
2. ボリューム作成
3. mcpo-bridge起動（複数レプリカ）
4. mcpo-bridgeヘルスチェック待機
5. nginx起動
6. openwebui起動
7. システム利用可能

### 13.6 再起動ポリシー

#### unless-stoppedポリシー

採用理由：
- 異常終了時の自動復旧
- ホスト再起動時の自動起動
- 手動停止時は再起動しない

## 14. MCP設定ファイル詳細仕様

### 14.1 設定ファイル配置

#### ファイルパス

- ソースコード配下：/app/config/mcp-servers.json
- サンプルファイル：/app/config/mcp-servers.json.example
- 環境変数で変更可能：MCPO_CONFIG_FILE

#### ファイル形式

- エンコーディング：UTF-8
- フォーマット：JSON
- スキーマバリデーション：起動時実施

### 14.2 設定ファイル構造詳細

#### ルートオブジェクト

- mcpServers：サーバー定義マップ（必須）

#### サーバー定義オブジェクト

各サーバーは以下のフィールドを持つ：

- command：実行バイナリパス（必須）
  - 絶対パスまたは相対パス
  - PATH環境変数で解決可能なコマンド名
- args：コマンドライン引数配列（必須、空配列可）
  - 文字列の配列
- env：環境変数マップ（オプション）
  - キーバリューペアのオブジェクト
  - サーバー実行時に設定
- timeout：タイムアウト秒数（オプション）
  - 個別サーバーのタイムアウト設定
  - グローバル設定を上書き

### 14.3 設定例

#### Office-PowerPoint-MCP-Server（Node.js製）

サンプル設定ではOffice-PowerPoint-MCP-Serverを使用：

- サーバー名：powerpoint
- コマンド：npx
- 引数：-y、@gongrzhe/office-powerpoint-mcp-server
- 環境変数：NODE_ENV=production

注意事項：
- office-powerpoint-mcp-serverはNode.js製（TypeScript）のMCPサーバーです
- DockerfileでNode.jsのインストールが必要です
- npx -y オプションにより、パッケージが自動的にダウンロード・実行されます

#### Excel-MCP-Server（Python製）

excel-mcp-serverは複数のトランスポート方式をサポートしています：

- サーバー名：excel
- コマンド：uvx
- 引数：excel-mcp-server、stdio
- 環境変数：なし

注意事項：
- excel-mcp-serverはPython製のMCPサーバーです
- Dockerfileでuvのインストールが必要です
- stdio引数は標準入出力で通信するモードを指定します
- uvxが自動的にPython環境を管理します

#### 複数サーバーの同時使用

Node.js製PowerPointサーバーとPython製Excelサーバーを同時に使用する場合の設定例：

**powerpointサーバー：**
- コマンド：npx
- 引数：-y、@gongrzhe/office-powerpoint-mcp-server
- 環境変数：NODE_ENV=production

**excelサーバー：**
- コマンド：uvx
- 引数：excel-mcp-server、stdio

この構成を使用する場合、Dockerfileで以下の両方をインストールする必要があります：
- Node.js（npx用）
- uv（uvx用）

### 14.4 設定リロード

#### 現行仕様

- 設定ファイル変更時はBridge再起動が必要
- 動的リロード機能なし

## 15. Nginx設定設計

### 15.1 ロードバランサー設定

#### アップストリーム定義

##### ステートレス用（デフォルト）

- mcpo-bridgeサービスの全レプリカを自動検出
- Docker DNSによる名前解決
- ラウンドロビンアルゴリズム

##### ステートフル用

- mcpo-bridgeサービスの全レプリカを自動検出
- Docker DNSによる名前解決
- ip_hashアルゴリズム（クライアントIPベースのスティッキーセッション）
- 詳細：セクション19.7「Nginx設定変更」を参照

#### ヘルスチェック

- 各Bridgeインスタンスの/healthエンドポイントを監視
- unhealthyなインスタンスを自動除外

### 15.2 静的ファイル配信設定

#### ロケーション設定

- パス：/files/
- ルート：バインドマウント ./data/mcpo-jobs
- ディレクトリリスティング：無効

#### シンプルな配信

- 有効期限チェックなし
- シンプルなファイル配信
- 404エラーは存在しないファイルのみ

### 15.3 プロキシ設定

#### MCPOエンドポイント

- パス：/mcpo/
- プロキシ先：mcpo-bridgeアップストリーム
- タイムアウト：600秒（長時間処理対応）

#### MCPエンドポイント

- パス：/mcp/
- プロキシ先：mcpo-bridgeアップストリーム
- タイムアウト：600秒

## 16. 運用設計

### 16.1 デプロイ手順

#### 初回デプロイ

1. リポジトリクローン
2. config/mcp-servers.json.example を config/mcp-servers.json にコピーして編集
3. docker-compose.yml 環境変数調整
4. docker-compose up -d 実行
5. ヘルスチェック確認
6. OpenWebUI アクセス確認

#### 更新デプロイ

1. 最新コードpull
2. docker-compose build 実行
3. docker-compose up -d 実行
4. ヘルスチェック確認
5. 動作確認

### 16.2 監視項目

#### サービス監視

- コンテナ稼働状態
- ヘルスチェック結果
- リスタート回数

#### リソース監視

- CPU使用率
- メモリ使用量
- ディスク使用量（バインドマウント）
- ネットワークトラフィック

#### アプリケーション監視

- リクエスト数
- エラー率
- レスポンスタイム
- 同時実行プロセス数

### 16.3 障害対応

#### コンテナ再起動

- docker-compose restart mcpo-bridge
- 自動再起動ポリシーにより自動復旧も可能

#### ログ確認

- docker-compose logs mcpo-bridge
- バインドマウントから直接確認（./data/mcpo-logs）
- エラー原因特定

#### ロールバック

- 前バージョンイメージへの切り戻し
- docker-compose down → イメージタグ変更 → up

### 16.4 スケールアウト

#### 手動スケール

- docker-compose.ymlのreplicas設定変更
- docker-compose up -d で反映
- Nginxが自動的に新インスタンスを検出

## 17. テスト設計

### 17.1 ユニットテスト

#### テスト対象

- ジョブ管理関数
- メタデータ生成関数

#### テストフレームワーク

- pytest
- モックライブラリ使用

### 17.2 統合テスト

#### テストシナリオ

- エンドツーエンドMCP/MCPOリクエスト処理
- ファイルダウンロード（Nginx経由）
- エラーハンドリング
- タイムアウト処理

#### テスト環境

- Docker Compose によるテスト環境構築
- モックMCPサーバー使用

### 17.3 負荷テスト

#### テストツール

- Apache Bench (ab)
- Locust
- k6

#### テスト項目

- 同時リクエスト数増加
- レスポンスタイム測定
- エラー率測定
- スケーリング効果確認

## 18. まとめ

本詳細設計書は、MCPO On-Demand MCP Bridgeシステムの実装に必要な全ての設計情報を網羅している。

### 主要な設計ポイント

- Nginxフロントエンドによる効率的なファイル配信とロードバランシング
- MCP/MCPOエンドポイントの明確な分離と複数サーバータイプ対応
- MCPレスポンスの透過的な転送（変更なし）
- 入力検証のMCPサーバーへの委譲
- Docker Compose replicasによる簡単なスケールアウト
- バインドマウントによるシンプルなストレージ管理
- Office-PowerPoint-MCP-Serverをuvxで起動する設定例
- シンプルで保守しやすい設計
- IPアドレスベースのステートフルMCPサーバー対応（セクション19）

本設計に基づき実装を進めることで、安全でスケーラブルなファイル生成系MCPサーバー基盤を構築できる。

## 19. ステートフルMCPサーバー対応設計

### 19.1 背景と目的

特定のMCPサーバー（office-powerpoint-mcp-serverなど）は、複数リクエスト間で状態（例：presentation_id）を保持する必要がある。Ephemeralモデルでは各リクエストでプロセスが終了するため、状態管理ができない。

**設計目標：**
- プロセスを複数リクエスト間で永続化
- 同一クライアントからのリクエストは同一プロセスで処理
- OpenWebUIの変更なしで実装可能

### 19.2 設計方針

#### 前提条件

✅ **必須前提：**
- クライアントIPアドレスは固定（NAT環境でもIPが変動しない）
- プライベートネットワークまたは社内ネットワーク環境での利用
- 信頼できるネットワーク環境

⚠️ **適用できない環境：**
- 複数ユーザーが同一NATを共有する環境
- モバイルネットワークなどIP変動が頻繁な環境
- パブリッククラウドで動的IPが割り当てられる環境

#### 採用方式

**クライアントIPアドレスベースのセッション管理：**
- Nginxの`ip_hash`ディレクティブで同一IPを同一Bridgeインスタンスへルーティング
- Bridge側でIPアドレスごとにプロセスプールを管理
- アイドルタイムアウトで自動プロセス終了

**OpenWebUIとの統合：**
- OpenWebUI側の変更は不要（現行の制約: ユーザー識別ヘッダーはMCP接続時に送信されない）
- Nginxが`X-Real-IP`および`X-Forwarded-For`ヘッダーを付与
- Bridge側でヘッダーからクライアントIPを抽出

### 19.3 全体アーキテクチャ

```
OpenWebUI (Client IP: 192.168.1.100)
   |
   | MCP Request
   v
Nginx (ip_hash load balancing)
   |
   | 同一IPは常に同一Bridgeインスタンスへルーティング
   | X-Real-IP: 192.168.1.100
   | X-Forwarded-For: 192.168.1.100
   v
MCPO Bridge Instance (例: instance-1)
   |
   | IP-based Process Pool
   |
   +-- 192.168.1.100 → PowerPoint Process (persistent, stateful)
   +-- 192.168.1.101 → PowerPoint Process (persistent, stateful)
   +-- 192.168.1.102 → PowerPoint Process (persistent, stateful)
```

### 19.4 MCPサーバー設定拡張

#### 設定ファイル（mcp-servers.json）

**powerpointサーバーの設定例：**
- コマンド：npx
- 引数：-y、@gongrzhe/office-powerpoint-mcp-server
- モード：stateful（ステートフル）
- アイドルタイムアウト：1800秒（30分）
- IPアドレスごとの最大プロセス数：1

**excelサーバーの設定例：**
- コマンド：uvx
- 引数：excel-mcp-server、stdio
- モード：stateless（ステートレス）

#### 新規フィールド仕様

| フィールド | 型 | 必須 | デフォルト | 説明 |
|---|---|---|---|---|
| mode | string | No | "stateless" | "stateful" または "stateless" |
| idle_timeout | integer | No | 1800 | アイドルタイムアウト秒数（30分） |
| max_processes_per_ip | integer | No | 1 | IPアドレスごとの最大プロセス数 |

**mode="stateful"の動作：**
- プロセスはリクエスト後も終了せず待機状態を維持
- 同一IPからの次回リクエストは既存プロセスを再利用
- `idle_timeout`経過後に自動終了

**mode="stateless"の動作：**
- 従来のEphemeralモデル（1リクエスト=1プロセス）
- リクエスト処理後に即座にプロセス終了

### 19.5 プロセスプール管理

#### データ構造

**グローバルプロセスプール：**

階層構造は以下の通り：
- 第1階層：サーバータイプ（例：powerpoint、excel）
- 第2階層：クライアントIPアドレス
- 第3階層：プロセス情報

**プロセス情報に含まれる項目：**
- process：実行中のサブプロセスオブジェクト
- stdin：標準入力ストリーム（リクエスト送信用）
- stdout：標準出力ストリーム（レスポンス受信用）
- stderr：標準エラー出力ストリーム
- last_access：最終アクセス日時（アイドルタイムアウト判定用）
- created_at：プロセス作成日時
- request_count：処理したリクエスト数
- idle_timeout：このプロセス固有のアイドルタイムアウト秒数

#### プロセスライフサイクル

**1. プロセス起動（初回リクエスト時）:**

条件判定：
- モードがステートフルである
- かつ、プロセスプールに該当クライアントIPのエントリが存在しない

処理内容：
- サーバー設定に基づき新規MCPサーバープロセスを起動
- プロセスプールに以下の情報を登録：
  - プロセスオブジェクト
  - 標準入力ストリーム
  - 標準出力ストリーム
  - 最終アクセス日時（現在時刻）
  - 作成日時（現在時刻）
  - リクエストカウント（0で初期化）

**2. プロセス再利用（2回目以降）:**

条件判定：
- モードがステートフルである
- かつ、プロセスプールに該当クライアントIPのエントリが存在する

処理内容：
- プロセスプールから該当IPのプロセス情報を取得
- プロセスの健全性チェックを実施

健全性チェック合格の場合：
- 既存プロセスを再利用
- 最終アクセス日時を現在時刻に更新
- リクエストカウントを1増加
- 既存プロセスにリクエストを送信

健全性チェック不合格の場合：
- 該当プロセスを終了
- プロセスプールからエントリを削除
- 新規プロセス起動処理に移行（上記1の処理を実行）

**3. プロセス終了（アイドルタイムアウト）:**

**バックグラウンドクリーンアップタスクの動作：**

定期実行間隔：
- 5分ごとに実行（環境変数MCPO_STATEFUL_CLEANUP_INTERVALで調整可能）

処理内容：
- 全サーバータイプを走査
- 各サーバータイプ内の全クライアントIPを走査
- 各プロセス情報について以下をチェック：
  - 現在時刻と最終アクセス日時の差分（アイドル時間）を計算
  - アイドル時間がidle_timeout設定値を超過しているか判定

タイムアウト超過の場合：
- 該当プロセスを終了（SIGTERM送信）
- プロセスプールから該当エントリを削除
- ログに終了情報を記録（サーバータイプ/クライアントIP）

### 19.6 クライアントIP抽出

#### 優先順位

**クライアントIPアドレス抽出関数の仕様：**

抽出の優先順位（上から順に試行）：

1. **X-Forwarded-Forヘッダーの利用**
   - HTTPリクエストヘッダーからX-Forwarded-Forを取得
   - ヘッダーが存在する場合：
     - カンマ区切りで分割
     - 最初のIPアドレスを抽出
     - 空白をトリムして返却

2. **X-Real-IPヘッダーの利用**
   - HTTPリクエストヘッダーからX-Real-IPを取得（Nginxが設定）
   - ヘッダーが存在する場合：
     - 空白をトリムして返却

3. **リクエストオブジェクトのクライアント情報を利用**
   - リクエストオブジェクトにclient属性が存在する場合：
     - client.host（直接接続時のIPアドレス）を返却

4. **フォールバック値**
   - 上記のいずれからもIPが取得できない場合：
     - 「unknown」文字列を返却

#### IP検証

**IPアドレスの妥当性検証関数の仕様：**

入力：
- IPアドレス文字列

処理：
- Pythonのipaddressモジュールを使用してパースを試みる
- パース成功時：Trueを返却
- パース失敗時（ValueError発生）：Falseを返却

### 19.7 Nginx設定変更

#### アップストリーム定義

**ステートフル用アップストリーム：**
- 名称：mcpo_bridge_stateful
- 負荷分散方式：ip_hash（同一IPアドレスを同一サーバーへルーティング）
- バックエンドサーバー：mcpo-bridge:8080
- 故障検知設定：
  - max_fails: 3（最大3回失敗で利用不可判定）
  - fail_timeout: 30秒（再試行までの待機時間）

**ステートレス用アップストリーム：**
- 名称：mcpo_bridge_stateless
- 負荷分散方式：ラウンドロビン（デフォルト）
- バックエンドサーバー：mcpo-bridge:8080
- 故障検知設定：
  - max_fails: 3
  - fail_timeout: 30秒

#### ロケーション設定（サーバータイプ別）

**ステートフルMCPサーバー（powerpoint）の設定：**
- パスパターン：/mcpo/powerpointで始まるパス
- プロキシ先：http://mcpo_bridge_stateful
- HTTPバージョン：1.1
- 設定するヘッダー：
  - Host: リクエストのホスト名
  - X-Real-IP: クライアントの実際IPアドレス
  - X-Forwarded-For: プロキシチェーン内の全IPアドレス
  - X-Forwarded-Proto: プロトコル（http/https）
- バッファリング：無効
- タイムアウト設定（長時間接続用）：
  - proxy_connect_timeout: 600秒
  - proxy_send_timeout: 600秒
  - proxy_read_timeout: 600秒

**ステートレスMCPサーバー（excel）の設定：**
- パスパターン：/mcpo/excelで始まるパス
- プロキシ先：http://mcpo_bridge_stateless
- その他の設定は上記powerpointと同様（タイムアウトはデフォルト値）

**デフォルト設定（その他のサーバータイプ）：**
- パスパターン：/mcpo/（サーバータイプ名）の形式
- プロキシ先：http://mcpo_bridge_stateless
- その他の設定は上記excelと同様

### 19.8 環境変数拡張

#### 新規環境変数

**MCPO_STATEFUL_ENABLED:**
- 説明：ステートフル機能の有効化
- 型：ブール値（true/false）
- デフォルト値：true

**MCPO_STATEFUL_DEFAULT_IDLE_TIMEOUT:**
- 説明：グローバル設定のアイドルタイムアウト秒数（mcp-servers.jsonの個別設定で上書き可能）
- 型：整数
- デフォルト値：1800（30分）

**MCPO_STATEFUL_MAX_PROCESSES_PER_IP:**
- 説明：クライアントIPアドレスごとの最大プロセス数
- 型：整数
- デフォルト値：1

**MCPO_STATEFUL_MAX_TOTAL_PROCESSES:**
- 説明：システム全体での最大ステートフルプロセス数
- 型：整数
- デフォルト値：100

**MCPO_STATEFUL_CLEANUP_INTERVAL:**
- 説明：クリーンアップタスクの実行間隔（秒数）
- 型：整数
- デフォルト値：300（5分）

#### docker-compose.yml追加例

**mcpo-bridgeサービスの環境変数設定：**
- MCPO_STATEFUL_ENABLEDをtrueに設定
- MCPO_STATEFUL_DEFAULT_IDLE_TIMEOUTを1800に設定
- MCPO_STATEFUL_MAX_PROCESSES_PER_IPを1に設定
- MCPO_STATEFUL_MAX_TOTAL_PROCESSESを100に設定
- MCPO_STATEFUL_CLEANUP_INTERVALを300に設定

### 19.9 処理フロー（ステートフルモード）

#### リクエスト受信時

**処理フローの詳細：**

1. **HTTPリクエスト受信**

2. **クライアントIP抽出**
   - X-Forwarded-Forヘッダーから抽出を試みる
   - 失敗時はX-Real-IPヘッダーを試行
   - さらに失敗時はrequest.client.hostを使用

3. **サーバータイプとmode確認**
   - mcp-servers.jsonから該当サーバーの設定を読み込み

4. **mode判定と分岐**

   **mode == "stateful"の場合（ステートフル処理）:**
   
   a. **プロセスプールチェック**
      - 該当IPのプロセスがプールに存在するか確認
   
   b-1. **既存プロセスが存在する場合:**
      - プロセス健全性チェックを実施
      
      - **健全な場合:**
        - 既存プロセスを再利用
        - リクエストをプロセスに送信
        - last_accessを現在時刻に更新
        - レスポンスを受信
      
      - **不健全な場合:**
        - プロセスを削除
        - 新規プロセス起動処理へ移行（下記b-2へ）
   
   b-2. **既存プロセスが存在しない場合:**
      - 新規MCPサーバープロセスを起動
      - プロセス情報をプールに登録
      - リクエストをプロセスに送信
      - レスポンスを受信
   
   c. **レスポンス返却**
      - クライアントにレスポンスを返却
      - 注意：プロセスは終了せずに待機状態を維持

   **mode == "stateless"の場合（ステートレス処理）:**
   
   a. **新規プロセス起動**
      - MCPサーバープロセスを起動
   
   b. **リクエスト処理**
      - リクエストをプロセスに送信
      - レスポンスを受信
   
   c. **プロセス終了**
      - プロセスを即座に終了
   
   d. **レスポンス返却**
      - クライアントにレスポンスを返却

#### バックグラウンドクリーンアップ

**バックグラウンドタスクの動作：**

1. **起動時にバックグラウンドタスク開始**

2. **ループ処理**
   
   a. **待機**
      - MCPO_STATEFUL_CLEANUP_INTERVAL秒間待機（デフォルト：5分）
   
   b. **全プロセスプールをスキャン**
      - 全サーバータイプを走査
   
   c. **各プロセスのlast_accessチェック**
      - 現在時刻とlast_accessの差分を計算
   
   d. **idle_timeout経過判定**
      
      - **タイムアウト経過の場合:**
        - SIGTERMシグナルをプロセスに送信
        - 10秒間待機
        - まだプロセスが生存しているか確認
        - 生存している場合はSIGKILLシグナルを送信
        - プロセスプールから削除
        - ログに終了情報を記録
      
      - **タイムアウト未経過の場合:**
        - スキップして次のプロセスをチェック
   
   e. **ループ継続**
      - 手順aに戻り繰り返す

### 19.10 エラーハンドリング

#### プロセス異常検出

**プロセス健全性チェック関数の仕様：**

入力：
- プロセスオブジェクト（subprocess.Popen）

チェック項目：

1. **プロセスの実行状態確認**
   - プロセスが終了していないかチェック（pollメソッドで確認）
   - 終了している場合：Falseを返却

2. **標準入出力パイプの有効性確認**
   - tryブロック内で以下をチェック：
     - process.stdinが閉じられていないか
     - process.stdoutが閉じられていないか
   - いずれかが閉じられている場合：Falseを返却
   - 例外が発生した場合：Falseを返却

3. **全テスト合格の場合**
   - Trueを返却（プロセスは健全）

#### リカバリ動作

**プロセス異常時の処理手順：**

1. **異常検出**
   - プロセスの予期せぬ終了を検出
   - パイプの切断を検出
   - タイムアウトの発生を検出

2. **プロセスをプールから即座に削除**
3. エラーログ記録
4. 次回リクエストで新規プロセス起動
5. クライアントには通常のエラーレスポンス返却

**プロセスプール上限到達時：**
1. `MCPO_STATEFUL_MAX_TOTAL_PROCESSES`到達検出
2. 429 Too Many Requests 返却
3. `Retry-After: 60`ヘッダー付与
4. クライアント側でリトライ推奨

### 19.11 制約事項と運用考慮

#### 技術的制約

| 制約 | 内容 | 影響 |
|---|---|---|
| IP固定前提 | クライアントIPが変動しない環境が必須 | モバイル環境では利用不可 |
| IP共有環境 | 複数ユーザーが同一NATを共有する場合、状態が混在 | 社内ネットワーク等での利用を推奨 |
| 負荷分散制限 | ip_hashにより特定インスタンスに負荷集中の可能性 | インスタンス数増加の効果に限界 |
| メモリ使用量 | ステートフルプロセスは常駐するためメモリ消費が増加 | `max_total_processes`で制限 |

#### セキュリティ考慮

**IPアドレスの信頼性：**
- IPアドレスは認証情報ではない（なりすまし可能）
- 信頼できるネットワーク環境（社内ネットワーク等）での使用を推奨
- 機密性の高いドキュメント生成には別途認証機構の実装を検討

**プロキシ環境：**
- Nginx以外のプロキシが前段にある場合、`X-Forwarded-For`ヘッダーの検証が必要
- プロキシチェーンの最初のIPを使用（カンマ区切りの先頭）

#### 運用推奨事項

**適切な環境：**
- ✅ 社内ネットワーク（固定IPまたは予測可能なIP割り当て）
- ✅ プライベートクラウド（VPC内の固定IP）
- ✅ 開発環境（ローカルネットワーク）

**不適切な環境：**
- ❌ パブリックインターネット（動的IP）
- ❌ モバイルネットワーク（頻繁なIP変動）
- ❌ 共有NAT環境（複数ユーザーが同一IP）

**監視項目：**
- ステートフルプロセス数（メトリクス）
- IPアドレスごとのリクエスト数
- アイドルタイムアウト発生率
- プロセス異常終了率

**パフォーマンスチューニング：**
- `idle_timeout`の調整（頻繁な利用: 短く、散発的な利用: 長く）
- `max_processes_per_ip`の調整（同時操作が必要な場合は増加）
- Bridge replicasの増加（ただしip_hashの制限あり）

**MCPO On-Demand Bridge 詳細設計書 v4.0**
