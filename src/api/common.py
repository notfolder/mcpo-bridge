"""
å…±é€šMCPå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

MCP/MCPOã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å…±é€šå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
"""
import asyncio
import logging
import os
from pathlib import Path
from typing import Any
from fastapi import Request, HTTPException, status

from src.core.job_manager import job_manager
from src.core.process_manager import process_manager
from src.core.config import mcp_config, settings
from src.models.job import JobStatus
from src.utils.network import extract_client_ip

logger = logging.getLogger(__name__)


def _extract_file_info(
    data: Any, 
    job_id: str, 
    base_url: str,
    file_path_fields: list[str]
) -> tuple[Any, list[dict]]:
    """
    ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æŠ½å‡ºã—ã¦Open WebUIå½¢å¼ã«å¤‰æ›
    
    Args:
        data: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆdict, list, ã¾ãŸã¯ä»–ã®å‹ï¼‰
        job_id: ã‚¸ãƒ§ãƒ–ID
        base_url: ãƒ™ãƒ¼ã‚¹URLï¼ˆä¾‹: http://nginxï¼‰
        file_path_fields: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æƒ…å ±ã‚’å«ã‚€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ãƒªã‚¹ãƒˆ
    
    Returns:
        (ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLæƒ…å ±ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿, ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ)
    """
    files = []
    
    def process_data(data: Any) -> Any:
        nonlocal files
        
        if isinstance(data, dict):
            # è¨­å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
            for field_name in file_path_fields:
                if field_name in data:
                    file_path = data[field_name]
                    
                    # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’è¿½åŠ 
                    if file_path and isinstance(file_path, str) and not os.path.isabs(file_path):
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
                        filename = Path(file_path).name
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’ç”Ÿæˆ
                        download_url = f"{base_url}/files/{job_id}/{filename}"
                        
                        # Open WebUIå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
                        files.append({
                            "type": "file",
                            "url": download_url,
                            "name": filename
                        })
                        
                        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚_download_urlã‚‚è¿½åŠ 
                        data["_download_url"] = download_url
                        logger.debug(f"Added file info for {field_name}={file_path}: {download_url}")
            
            # ãƒã‚¹ãƒˆã•ã‚ŒãŸè¾æ›¸ã‚‚å†å¸°çš„ã«å‡¦ç†
            for key, value in data.items():
                data[key] = process_data(value)
        
        elif isinstance(data, list):
            # ãƒªã‚¹ãƒˆå†…ã®å„è¦ç´ ã‚’å†å¸°çš„ã«å‡¦ç†
            data = [process_data(item) for item in data]
        
        return data
    
    processed_data = process_data(data)
    return processed_data, files


async def process_mcp_request(
    server_type: str,
    request: Request,
    protocol_name: str = "MCP"
) -> dict:
    """
    MCP/MCPOãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å…±é€šå‡¦ç†
    
    Args:
        server_type: MCPã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ—ï¼ˆä¾‹: "powerpoint"ï¼‰
        request: FastAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        protocol_name: ãƒ—ãƒ­ãƒˆã‚³ãƒ«åï¼ˆãƒ­ã‚°ç”¨ã€"MCP"ã¾ãŸã¯"MCPO"ï¼‰
    
    Returns:
        MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆJSONï¼‰
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å–å¾—
    file_path_fields = mcp_config.get_file_path_fields(server_type)
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIPã‚’æŠ½å‡º
    client_ip = extract_client_ip(request)
    logger.info(f"{protocol_name} request from {client_ip} for server type: {server_type}")
    
    # ã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ—ã®å­˜åœ¨ç¢ºèª
    if not mcp_config.get_server_config(server_type):
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Unknown server type: {server_type}"
        )
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’å–å¾—
    try:
        request_data = await request.json()
        logger.debug(f"MCP request data: {request_data}")
    except Exception as e:
        logger.error(f"Failed to parse request JSON: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid JSON in request body"
        )
    
    # ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
    job_id, job_dir = job_manager.create_job(server_type, client_ip)
    
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¿å­˜
        job_manager.save_request(job_id, request_data)
        
        # MCPã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        response_data, exit_code = await process_manager.execute_request(
            server_type=server_type,
            request_data=request_data,
            job_dir=job_dir,
            client_ip=client_ip if settings.stateful_enabled else None
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
        job_manager.save_response(job_id, response_data)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        logger.debug(f"MCP response for job {job_id}: {response_data}")
        
        # ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
        if exit_code == 0:
            job_manager.update_status(job_id, JobStatus.COMPLETED)
        else:
            job_manager.update_status(
                job_id,
                JobStatus.FAILED,
                f"Process exited with code {exit_code}"
            )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã¨ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
        response_data, files = _extract_file_info(
            response_data, 
            job_id, 
            settings.base_url,
            file_path_fields
        )
        
        # Open WebUIå½¢å¼: contentã«filesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¡ˆå†…ã‚’è¿½åŠ 
        if files and isinstance(response_data, dict):
            if "result" in response_data:
                # MCPãƒ„ãƒ¼ãƒ«å¿œç­”ã®å ´åˆ
                if "content" in response_data["result"]:
                    # contentãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
                    if isinstance(response_data["result"]["content"], list):
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¡ˆå†…ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…ˆé ­ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
                        for item in response_data["result"]["content"]:
                            if item.get("type") == "text" and "text" in item:
                                # æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯æƒ…å ±ã‚’è¿½åŠ 
                                download_links = "\n\n" + "\n".join([
                                    f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: [{f['name']}]({f['url']})" 
                                    for f in files
                                ])
                                item["text"] += download_links
                                break
                        
                        # filesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚è¿½åŠ 
                        response_data["result"]["content"].append({
                            "type": "files",
                            "files": files
                        })
                else:
                    # contentãŒãªã„å ´åˆã¯ä½œæˆ
                    download_text = "\n".join([
                        f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: [{f['name']}]({f['url']})" 
                        for f in files
                    ])
                    response_data["result"]["content"] = [
                        {
                            "type": "text",
                            "text": download_text
                        },
                        {
                            "type": "files",
                            "files": files
                        }
                    ]
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”å´
        return response_data
    
    except asyncio.TimeoutError:
        logger.error(f"Timeout processing {protocol_name} request for job {job_id}")
        job_manager.update_status(job_id, JobStatus.FAILED, "Timeout")
        raise HTTPException(
            status_code=status.HTTP_504_GATEWAY_TIMEOUT,
            detail="MCP server request timeout"
        )
    
    except Exception as e:
        logger.error(f"Error processing {protocol_name} request for job {job_id}: {e}")
        job_manager.update_status(job_id, JobStatus.FAILED, str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {str(e)}"
        )
